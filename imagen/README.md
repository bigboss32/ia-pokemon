# Pokemon Multi-Label Classifier

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa un clasificador multi-etiqueta para PokÃ©mon utilizando deep learning. El modelo es capaz de identificar mÃºltiples tipos de PokÃ©mon en una sola imagen (por ejemplo, un PokÃ©mon puede ser tanto "Water" como "Flying").

## ğŸ—ï¸ Arquitectura del Modelo

### Red Neuronal Base
- **Modelo:** ResNet-18 pre-entrenado en ImageNet
- **Backbone:** Convolutional Neural Network con 18 capas
- **Transfer Learning:** Utiliza pesos pre-entrenados de ImageNet para aprovechar caracterÃ­sticas visuales ya aprendidas

### Modificaciones para Multi-Label
- **Capa de Salida:** Reemplaza la capa fully connected final con una nueva capa linear
- **Dimensiones de Salida:** 18 neuronas (una por cada tipo de PokÃ©mon)
- **FunciÃ³n de ActivaciÃ³n:** Sigmoid aplicada durante la inferencia (no en el entrenamiento)
- **FunciÃ³n de PÃ©rdida:** BCEWithLogitsLoss (Binary Cross-Entropy with Logits)

### Tipos de PokÃ©mon Soportados
```
normal, fire, water, electric, grass, ice, fighting, poison, 
ground, flying, psychic, bug, rock, ghost, dragon, dark, steel, fairy
```

## ğŸ”§ Componentes TÃ©cnicos

### Preprocesamiento de Datos
```python
transforms.Compose([
    transforms.Resize((224, 224)),          # Redimensiona a entrada estÃ¡ndar
    transforms.RandomHorizontalFlip(),      # AugmentaciÃ³n: flip horizontal
    transforms.RandomRotation(10),          # AugmentaciÃ³n: rotaciÃ³n Â±10Â°
    transforms.ToTensor(),                  # ConversiÃ³n a tensor
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # NormalizaciÃ³n ImageNet
])
```

### ConfiguraciÃ³n de Entrenamiento
- **Batch Size:** 16
- **Ã‰pocas:** 50
- **Optimizador:** Adam con learning rate 1e-5
- **DivisiÃ³n de Datos:** 80% entrenamiento, 20% validaciÃ³n
- **Fine-tuning:** Completo (todos los parÃ¡metros entrenables)

### Umbral de DecisiÃ³n
- **Threshold:** 0.5 para convertir probabilidades en predicciones binarias
- **Criterio:** `sigmoid(output) > 0.5` determina si un tipo estÃ¡ presente

## ğŸ“Š MÃ©tricas de EvaluaciÃ³n

El modelo evalÃºa su rendimiento usando mÃºltiples mÃ©tricas:

- **Accuracy:** PrecisiÃ³n por imagen (porcentaje de tipos correctamente clasificados)
- **Precision:** PrecisiÃ³n macro-promedio entre todos los tipos
- **Recall:** Recall macro-promedio entre todos los tipos  
- **F1-Score:** Media armÃ³nica entre precisiÃ³n y recall

## ğŸ“ Estructura del Proyecto

```
proyecto/
â”œâ”€â”€ pokemon_images_by_type/     # Dataset organizado por tipos
â”œâ”€â”€ uno.py                      # Clase PokemonMultiLabelDataset
â”œâ”€â”€ main.py                     # Script principal de entrenamiento
â”œâ”€â”€ pokemon_multi_label.pth     # Modelo entrenado (generado)
â”œâ”€â”€ training_metrics.csv        # MÃ©tricas por Ã©poca (generado)
â”œâ”€â”€ loss_curve.png             # GrÃ¡fica de pÃ©rdida (generado)
â”œâ”€â”€ accuracy_curve.png         # GrÃ¡fica de precisiÃ³n (generado)
â””â”€â”€ predictions/               # Ejemplos de predicciones (generado)
```

## ğŸš€ Uso del Modelo

### Entrenamiento
```bash
python main.py
```

### Salidas Generadas
1. **Modelo entrenado:** `pokemon_multi_label.pth`
2. **MÃ©tricas:** `training_metrics.csv` con histÃ³rico de entrenamiento
3. **GrÃ¡ficas:** Curvas de pÃ©rdida y precisiÃ³n
4. **Predicciones:** 5 ejemplos visuales en carpeta `predictions/`

### Inferencia
```python
# Cargar modelo
model = models.resnet18()
model.fc = nn.Linear(model.fc.in_features, 18)
model.load_state_dict(torch.load("pokemon_multi_label.pth"))
model.eval()

# Predecir
with torch.no_grad():
    outputs = model(image_tensor)
    probabilities = torch.sigmoid(outputs)
    predictions = probabilities > 0.5
```

## ğŸ¯ CaracterÃ­sticas Clave

- **Multi-Label:** Puede predecir mÃºltiples tipos simultÃ¡neamente
- **Data Augmentation:** Mejora la generalizaciÃ³n del modelo
- **Transfer Learning:** Acelera el entrenamiento y mejora el rendimiento
- **Monitoreo Completo:** Registra mÃºltiples mÃ©tricas durante el entrenamiento
- **VisualizaciÃ³n:** Genera grÃ¡ficas y ejemplos de predicciones

## âš™ï¸ Requisitos

- PyTorch
- torchvision
- scikit-learn
- matplotlib
- numpy

## ğŸ“ˆ Optimizaciones Implementadas

1. **Early Stopping:** Guarda el mejor modelo basado en validation loss
2. **Learning Rate Bajo:** 1e-5 para fine-tuning estable
3. **NormalizaciÃ³n:** Usa estadÃ­sticas de ImageNet para mejor transferencia
4. **Batch Processing:** Procesamiento eficiente por lotes